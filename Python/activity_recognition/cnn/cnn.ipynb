{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import DataCsv3\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5026, 77, 9)\n",
      "[  1.14220446e-02   6.49210334e-01  -4.22500014e-01   1.30463101e-04\n",
      "   4.21474010e-01   1.78506255e-01   1.49015534e-06   2.73625284e-01\n",
      "  -7.54188895e-02]\n"
     ]
    }
   ],
   "source": [
    "x,y = DataCsv.data_csv()\n",
    "\n",
    "x=x.astype(np.float32)\n",
    "y=y.astype(np.int32)\n",
    "print(x.shape)\n",
    "print(x[0,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is x.shape: (5026, 77, 9) 5026\n",
      "This is y.shape|len: (5026, 1) 5026\n",
      "This is n_values: 7\n"
     ]
    }
   ],
   "source": [
    "print('This is x.shape:',x.shape,len(x))\n",
    "print('This is y.shape|len:',y.shape,len(y))\n",
    "n_values = int(np.max(y)) + 1\n",
    "print('This is n_values:',n_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int32\n"
     ]
    }
   ],
   "source": [
    "print(y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#from sklearn.cross_validation import train_test_split\n",
    "#x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2)\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "sss=StratifiedShuffleSplit(y,test_size=0.2,train_size=0.8,random_state=0)\n",
    "for  train_index,test_index  in  sss:\n",
    "    x_train, x_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5],\n",
       "       [3],\n",
       "       [3],\n",
       "       [4],\n",
       "       [3],\n",
       "       [1],\n",
       "       [4],\n",
       "       [5],\n",
       "       [1],\n",
       "       [3]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2],\n",
       "       [2],\n",
       "       [3],\n",
       "       [1],\n",
       "       [4],\n",
       "       [2],\n",
       "       [3],\n",
       "       [2],\n",
       "       [1],\n",
       "       [4]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)  \n",
    "    return tf.Variable(initial)\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                        strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def deepnn(x):\n",
    "    with tf.name_scope('reshape'):\n",
    "        x_image = tf.reshape(x, [-1, 77, 9, 1])\n",
    "\n",
    "  # First convolutional layer - maps one grayscale image to 32 feature maps.\n",
    "    with tf.name_scope('conv1'):\n",
    "        W_conv1 = weight_variable([9, 3, 1, 5])\n",
    "        b_conv1 = bias_variable([5])\n",
    "        h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "\n",
    "  # Pooling layer - downsamples by 2X.\n",
    "    with tf.name_scope('pool1'):\n",
    "        h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "  # Second convolutional layer -- maps 32 feature maps to 64.\n",
    "    with tf.name_scope('conv2'):\n",
    "        W_conv2 = weight_variable([7, 3, 5, 10])\n",
    "        b_conv2 = bias_variable([10])\n",
    "        h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "\n",
    "  # Second pooling layer.\n",
    "    with tf.name_scope('pool2'):\n",
    "        h_pool2 = max_pool_2x2(h_conv2)\n",
    "        print(h_pool2.shape)\n",
    "        \n",
    "    with tf.name_scope('conv3'):\n",
    "        W_conv3 = weight_variable([5, 3, 10, 20])\n",
    "        b_conv3 = bias_variable([20])\n",
    "        h_conv3 = tf.nn.relu(conv2d(h_pool2, W_conv3) + b_conv3)\n",
    "\n",
    "  # Pooling layer - downsamples by 2X.\n",
    "    with tf.name_scope('pool3'):\n",
    "        h_pool3 = max_pool_2x2(h_conv3)\n",
    "  # Fully connected layer 1 -- after 2 round of downsampling, our 28x28 image\n",
    "  # is down to 7x7x64 feature maps -- maps this to 1024 features.\n",
    "    with tf.name_scope('fc1'):\n",
    "        W_fc1 = weight_variable([10 * 2* 20, 200])\n",
    "        b_fc1 = bias_variable([200])\n",
    "\n",
    "        h_pool3_flat = tf.reshape(h_pool3, [-1, 10*2*20])\n",
    "        h_fc1 = tf.nn.relu(tf.matmul(h_pool3_flat, W_fc1) + b_fc1)\n",
    "\n",
    "  # Dropout - controls the complexity of the model, prevents co-adaptation of\n",
    "  # features.\n",
    "    with tf.name_scope('dropout'):\n",
    "        keep_prob = tf.placeholder(tf.float32)\n",
    "        h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "  # Map the 1024 features to 10 classes, one for each digit\n",
    "    with tf.name_scope('fc2'):\n",
    "        W_fc2 = weight_variable([200, 7])\n",
    "        b_fc2 = bias_variable([7])\n",
    "\n",
    "        y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "        return y_conv, keep_prob\n",
    "    \n",
    "def extract_batch_size(_train, step, batch_size):\n",
    "    \n",
    "    shape = list(_train.shape) #_X  7352 128 9\n",
    "    shape[0] = batch_size      # 1500 128 9\n",
    "    batch_s = np.empty(shape)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        index = ((step-1)*batch_size + i) % len(_train) # step=1 \n",
    "        batch_s[i] = _train[index] \n",
    "\n",
    "    return batch_s \n",
    "\n",
    "def one_hot(y_):\n",
    "    y_ = y_.reshape(len(y_))\n",
    "    #n_values = int(np.max(y_)) + 1\n",
    "    n_values = 7\n",
    "    return np.eye(n_values)[np.array(y_, dtype=np.int32)]  # Returns FLOATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "     \n",
    "    x = tf.placeholder(tf.float32, [None, 77,9])\n",
    "\n",
    "    y_ = tf.placeholder(tf.float32, [None, 7])\n",
    "\n",
    "    y_conv, keep_prob = deepnn(x)\n",
    "\n",
    "    with tf.name_scope('loss'):\n",
    "        \n",
    "        cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=y_,\n",
    "                                                            logits=y_conv)\n",
    "        cross_entropy = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "    with tf.name_scope('adam_optimizer'):\n",
    "        train_step = tf.train.AdamOptimizer(1e-3).minimize(cross_entropy)\n",
    "\n",
    "    with tf.name_scope('accuracy'):\n",
    "        correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "        correct_prediction = tf.cast(correct_prediction, tf.float32)\n",
    "        accuracy = tf.reduce_mean(correct_prediction)\n",
    "\n",
    "    graph_location=\"/tmp/tensorboard\"\n",
    "    print('Saving graph to: %s' % graph_location)\n",
    "    train_writer = tf.summary.FileWriter(graph_location)\n",
    "    train_writer.add_graph(tf.get_default_graph())\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for i in range(5600):\n",
    "            x_batch = extract_batch_size(x_train, i, 200)\n",
    "            y_batch = one_hot(extract_batch_size(y_train, i, 200))\n",
    "        \n",
    "            if i % 200 == 0:\n",
    "                #x_batc = extract_batch_size(x_test, i, 200)\n",
    "                #y_batc = one_hot(extract_batch_size(y_test, i, 200))\n",
    "                \n",
    "                train_accuracy = accuracy.eval(feed_dict={\n",
    "                x: x_batch, y_: y_batch, keep_prob: 1.0})\n",
    "                print('step %d, training accuracy %g' % (i, train_accuracy))\n",
    "                #train_accuracies.append(train_accuracy)\n",
    "                loss=sess.run(cross_entropy,feed_dict={x: x_batch, y_: y_batch, keep_prob: 0.5})\n",
    "                train_losses.append(loss) \n",
    "                print (\"test accuracy %g\"%accuracy.eval(feed_dict={x: x_test, y_: one_hot(y_test), keep_prob: 1.0}))\n",
    "            train_step.run(feed_dict={x: x_batch, y_: y_batch, keep_prob: 0.5})\n",
    "        pre = sess.run(y_conv,feed_dict={x: x_test, keep_prob: 1.0})\n",
    "        pres.append(np.argmax(pre,axis=1))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----pre---- [] 0\n",
      "-------------------------\n",
      "(?, 20, 3, 10)\n",
      "Saving graph to: /tmp/tensorboard\n",
      "step 0, training accuracy 0.13\n",
      "test accuracy 0.142147\n",
      "step 200, training accuracy 0.75\n",
      "test accuracy 0.727634\n",
      "step 400, training accuracy 0.875\n",
      "test accuracy 0.835984\n",
      "step 600, training accuracy 0.92\n",
      "test accuracy 0.870775\n",
      "step 800, training accuracy 0.915\n",
      "test accuracy 0.892644\n",
      "step 1000, training accuracy 0.955\n",
      "test accuracy 0.904573\n",
      "step 1200, training accuracy 0.97\n",
      "test accuracy 0.905567\n",
      "step 1400, training accuracy 0.955\n",
      "test accuracy 0.918489\n",
      "step 1600, training accuracy 0.98\n",
      "test accuracy 0.913519\n",
      "step 1800, training accuracy 0.97\n",
      "test accuracy 0.907555\n",
      "step 2000, training accuracy 0.985\n",
      "test accuracy 0.909543\n",
      "step 2200, training accuracy 0.98\n",
      "test accuracy 0.916501\n",
      "step 2400, training accuracy 0.985\n",
      "test accuracy 0.917495\n",
      "step 2600, training accuracy 0.99\n",
      "test accuracy 0.913519\n",
      "step 2800, training accuracy 0.995\n",
      "test accuracy 0.919483\n",
      "step 3000, training accuracy 0.99\n",
      "test accuracy 0.922465\n",
      "step 3200, training accuracy 0.995\n",
      "test accuracy 0.915507\n",
      "step 3400, training accuracy 0.99\n",
      "test accuracy 0.908549\n",
      "step 3600, training accuracy 0.995\n",
      "test accuracy 0.908549\n",
      "step 3800, training accuracy 1\n",
      "test accuracy 0.920477\n",
      "step 4000, training accuracy 0.995\n",
      "test accuracy 0.924453\n",
      "step 4200, training accuracy 1\n",
      "test accuracy 0.928429\n",
      "step 4400, training accuracy 0.995\n",
      "test accuracy 0.921471\n",
      "step 4600, training accuracy 0.995\n",
      "test accuracy 0.922465\n",
      "step 4800, training accuracy 1\n",
      "test accuracy 0.922465\n",
      "step 5000, training accuracy 1\n",
      "test accuracy 0.922465\n",
      "step 5200, training accuracy 0.995\n",
      "test accuracy 0.926441\n",
      "step 5400, training accuracy 1\n",
      "test accuracy 0.919483\n",
      "[2.0293882, 0.75584227, 0.49716321, 0.33069056, 0.28627264, 0.20804602, 0.18047918, 0.16259696, 0.14654821, 0.12720862, 0.10977092, 0.093251608, 0.082885087, 0.089609429, 0.030198036, 0.052285094, 0.05191737, 0.057607498, 0.066245832, 0.041004419, 0.042399563, 0.043926191, 0.051059678, 0.034865513, 0.032323126, 0.032066669, 0.019160265, 0.03429164]\n"
     ]
    }
   ],
   "source": [
    "train_losses=[]\n",
    "#train_accuracies=[]\n",
    "pres = []\n",
    "print('-----pre----',pres,len(pres))\n",
    "print('-------------------------')\n",
    "main()\n",
    "print(train_losses)\n",
    "#print(train_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 2 1 ..., 1 5 4]\n",
      "[3 6 1 ..., 1 5 4]\n",
      "Confusion Matrix:\n",
      "[[ 35   0   0   0   0   0   0]\n",
      " [  0 283   5   6   6   2   0]\n",
      " [  0  10 129   0   4   0   0]\n",
      " [  0   5   0 223   1   1   0]\n",
      " [  1   8   5   0 164   0   0]\n",
      " [  0   7   1   6   3  85   1]\n",
      " [  0   1   2   0   0   0  12]]\n",
      "\n",
      "Confusion matrix (normalised to % of total test data):\n",
      "[[  3.47912526   0.           0.           0.           0.           0.\n",
      "    0.        ]\n",
      " [  0.          28.13121414   0.49701789   0.59642148   0.59642148\n",
      "    0.19880715   0.        ]\n",
      " [  0.           0.99403578  12.82306194   0.           0.3976143    0.\n",
      "    0.        ]\n",
      " [  0.           0.49701789   0.          22.16699791   0.09940358\n",
      "    0.09940358   0.        ]\n",
      " [  0.09940358   0.7952286    0.49701789   0.          16.30218697   0.\n",
      "    0.        ]\n",
      " [  0.           0.69582504   0.09940358   0.59642148   0.29821074\n",
      "    8.44930458   0.09940358]\n",
      " [  0.           0.09940358   0.19880715   0.           0.           0.\n",
      "    1.19284296]]\n"
     ]
    }
   ],
   "source": [
    "pres = np.array(pres)\n",
    "pres = pres.astype(np.int32)\n",
    "pres = pres.reshape(1006)\n",
    "y_test = y_test.reshape(1006)\n",
    "\n",
    "print(pres)\n",
    "print(y_test)\n",
    "from sklearn import metrics\n",
    "print(\"Confusion Matrix:\")\n",
    "confusion_matrix = metrics.confusion_matrix(y_test, pres)\n",
    "print(confusion_matrix)\n",
    "normalised_confusion_matrix = np.array(confusion_matrix, dtype=np.float32)/np.sum(confusion_matrix)*100\n",
    "\n",
    "print(\"\")\n",
    "print(\"Confusion matrix (normalised to % of total test data):\")\n",
    "print(normalised_confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "       walk       0.97      1.00      0.99        35\n",
      "      bweep       0.90      0.94      0.92       302\n",
      "      clean       0.91      0.90      0.91       143\n",
      "      sweep       0.95      0.97      0.96       230\n",
      "      daily       0.92      0.92      0.92       178\n",
      "       dump       0.97      0.83      0.89       103\n",
      "        run       0.92      0.80      0.86        15\n",
      "\n",
      "avg / total       0.93      0.93      0.93      1006\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "target_names = ['walk','bweep','clean','sweep','daily','dump','run']\n",
    "print(classification_report(y_test,pres,target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc7fe3bfa20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(train_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
